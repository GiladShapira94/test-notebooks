{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94563f92",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training A `PyTorch` Classifier With And Without `Horovod`\n",
    "\n",
    "This test uses MNIST dataset to train a model using PyTorch with and without Horovod. Later it will verify that:\n",
    "\n",
    "  * The accuracy was not damaged in Horovod.\n",
    "  * The Horovod run was faster (only possible on big data). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbebf9dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## General Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Image versions: torch==1.13.0 torchvision==0.14.0\n",
    "# Test is set to install latest to make sure we are always up-to-date with the latest releases.\n",
    "!pip install plotly torch torchvision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0793f908",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path of the directory to save the data in:\n",
    "DATA_PATH = os.path.abspath(\"./data\")\n",
    "\n",
    "# Path of the directory to save the code in:\n",
    "SCRIPTS_PATH = os.path.abspath(\"./scripts\")\n",
    "\n",
    "# Number of epochs to train (to increase the training time without increasing the memory usage):\n",
    "N_EPOCHS = 4\n",
    "\n",
    "# Number of ranks (horovod workers) to deploy for the open mpi job:\n",
    "N_RANKS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f5825e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Prepare the directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a129333",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "os.makedirs(SCRIPTS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc9067e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Training Code\n",
    "\n",
    "1. Get the MNIST data from `torchvision.datasets`.\n",
    "2. Initialize a model.\n",
    "3. Run training on the training set with validation on the testing set.\n",
    "\n",
    "Accuracy score will be logged as a result as part of MLRun auto-logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56f847c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./scripts/mnist_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {SCRIPTS_PATH}/mnist_trainer.py\n",
    "from typing import Tuple\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import mlrun\n",
    "import mlrun.frameworks.pytorch as mlrun_torch\n",
    "\n",
    "\n",
    "def get_datasets(data_path: str, batch_size: int) -> Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
    "    # Download the data:\n",
    "    train_set = torchvision.datasets.MNIST(\n",
    "        os.path.join(data_path, \"mnist_training_files\"),\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    test_set = torchvision.datasets.MNIST(\n",
    "        os.path.join(data_path, \"mnist_validation_files\"),\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    # Initialize data loaders:\n",
    "    train_set = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    test_set = torch.utils.data.DataLoader(\n",
    "        test_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    return train_set, test_set\n",
    "\n",
    "\n",
    "class MNISTModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        \n",
    "        # Add the layers:\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(in_features=784, out_features=128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=128, out_features=128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=128, out_features=10),\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    \n",
    "def accuracy(y_pred: torch.Tensor, y_true: torch.Tensor):\n",
    "    return sum((torch.argmax(y_pred, 1) - y_true) == 0) / len(y_true)\n",
    "    \n",
    "\n",
    "@mlrun.handler(outputs=[\"time\"])\n",
    "def train(context: mlrun.MLClientCtx, scripts_path: str, data_path: str, n_epochs: int):\n",
    "    # Start the timer:\n",
    "    run_time = time.time()\n",
    "    \n",
    "    # Get the data:\n",
    "    batch_size = 32\n",
    "    train_set, test_set = get_datasets(\n",
    "        data_path=data_path, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    # Initialize the model:\n",
    "    model = MNISTModel()\n",
    "    \n",
    "    # Initialize optimizer and loss:\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train:\n",
    "    mlrun_torch.train(\n",
    "        model=model, \n",
    "        training_set=train_set,\n",
    "        loss_function=loss_function,\n",
    "        optimizer=optimizer,\n",
    "        validation_set=test_set,\n",
    "        metric_functions=[accuracy],\n",
    "        epochs=n_epochs,\n",
    "        use_cuda=False,\n",
    "        custom_objects_map={\"mnist_trainer.py\": \"MNISTModel\"},\n",
    "        custom_objects_directory=scripts_path,\n",
    "        context=context\n",
    "    )\n",
    "    run_time = time.time() - run_time\n",
    "    \n",
    "    return run_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576ebf20",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Create a Project\n",
    "\n",
    "1. Create the MLRun project.\n",
    "2. Create an MLRun function of the training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc42aedd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import mlrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fef3a7b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-12-26 13:45:02,984 [info] loaded project horovod-pytorch-test from MLRun DB\n"
     ]
    }
   ],
   "source": [
    "# Create the project:\n",
    "project = mlrun.get_or_create_project(name=\"horovod-pytorch-test\", context=\"./\", user_project=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b7d9c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the job function:\n",
    "job_function = project.set_function(os.path.join(SCRIPTS_PATH, \"mnist_trainer.py\"), name=\"train_job\", kind=\"job\", image=\"mlrun/ml-models\", handler=\"train\")\n",
    "job_function.apply(mlrun.auto_mount())\n",
    "\n",
    "# Create the open mpi function:\n",
    "mpijob_function = project.set_function(os.path.join(SCRIPTS_PATH, \"mnist_trainer.py\"), name=\"train_mpijob\", kind=\"mpijob\", image=\"mlrun/ml-models\", handler=\"train\")\n",
    "mpijob_function.apply(mlrun.auto_mount())\n",
    "mpijob_function.spec.replicas = N_RANKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f2448",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Run As A Job\n",
    "\n",
    "Run the training as a `job` and storing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5df0e44e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-12-26 13:45:03,086 [info] starting run training_job uid=2e706fcac6014bfdb5b6f3c3a1ad4682 DB=http://mlrun-api:8080\n",
      "Epoch  1/12:\n",
      "Training: 100% |██████████| 1875/1875 [00:21<00:00, 86.89Batch/s, CrossEntropyLoss=1.66, accuracy=0.844] \n",
      "Validating: 100% |██████████| 313/313 [00:03<00:00, 97.14Batch/s, CrossEntropyLoss=1.74, accuracy=0.688] \n",
      "\n",
      "Summary:\n",
      "+------------------+--------------------+\n",
      "|     Metrics      |       Values       |\n",
      "+------------------+--------------------+\n",
      "| CrossEntropyLoss | 1.7301945686340332 |\n",
      "|     accuracy     |       0.8125       |\n",
      "+------------------+--------------------+\n",
      "\n",
      "Epoch  2/12:\n",
      "Training: 100% |██████████| 1875/1875 [00:21<00:00, 85.87Batch/s, CrossEntropyLoss=1.7, accuracy=0.75]   \n",
      "Validating: 100% |██████████| 313/313 [00:03<00:00, 100.46Batch/s, CrossEntropyLoss=1.62, accuracy=0.875]\n",
      "\n",
      "Summary:\n",
      "+------------------+--------------------+\n",
      "|     Metrics      |       Values       |\n",
      "+------------------+--------------------+\n",
      "| CrossEntropyLoss | 1.6386646032333374 |\n",
      "|     accuracy     |      0.90625       |\n",
      "+------------------+--------------------+\n",
      "\n",
      "Epoch  3/12:\n",
      "Training: 100% |██████████| 1875/1875 [00:22<00:00, 84.12Batch/s, CrossEntropyLoss=1.56, accuracy=0.906] \n",
      "Validating: 100% |██████████| 313/313 [00:03<00:00, 96.92Batch/s, CrossEntropyLoss=1.57, accuracy=0.938] \n",
      "\n",
      "Summary:\n",
      "+------------------+--------------------+\n",
      "|     Metrics      |       Values       |\n",
      "+------------------+--------------------+\n",
      "| CrossEntropyLoss | 1.5732022523880005 |\n",
      "|     accuracy     |      0.96875       |\n",
      "+------------------+--------------------+\n",
      "\n",
      "Epoch  4/12:\n",
      "Training: 100% |██████████| 1875/1875 [00:21<00:00, 85.70Batch/s, CrossEntropyLoss=1.57, accuracy=0.875] \n",
      "Validating: 100% |██████████| 313/313 [00:02<00:00, 109.37Batch/s, CrossEntropyLoss=1.52, accuracy=1]    \n",
      "\n",
      "Summary:\n",
      "+------------------+--------------------+\n",
      "|     Metrics      |       Values       |\n",
      "+------------------+--------------------+\n",
      "| CrossEntropyLoss | 1.5571571588516235 |\n",
      "|     accuracy     |      0.96875       |\n",
      "+------------------+--------------------+\n",
      "\n",
      "Epoch  5/12:\n",
      "Training: 100% |██████████| 1875/1875 [00:23<00:00, 80.89Batch/s, CrossEntropyLoss=1.53, accuracy=0.969] \n",
      "Validating: 100% |██████████| 313/313 [00:03<00:00, 96.50Batch/s, CrossEntropyLoss=1.51, accuracy=0.938] \n",
      "\n",
      "Summary:\n",
      "+------------------+--------------------+\n",
      "|     Metrics      |       Values       |\n",
      "+------------------+--------------------+\n",
      "| CrossEntropyLoss | 1.5477045774459839 |\n",
      "|     accuracy     |      0.96875       |\n",
      "+------------------+--------------------+\n",
      "\n",
      "Epoch  6/12:\n",
      "Training: 100% |██████████| 1875/1875 [00:22<00:00, 82.09Batch/s, CrossEntropyLoss=1.5, accuracy=0.969]  \n",
      "Validating: 100% |██████████| 313/313 [00:03<00:00, 97.50Batch/s, CrossEntropyLoss=1.51, accuracy=0.938] \n",
      "\n",
      "Summary:\n",
      "+------------------+-------------------+\n",
      "|     Metrics      |      Values       |\n",
      "+------------------+-------------------+\n",
      "| CrossEntropyLoss | 1.542940378189087 |\n",
      "|     accuracy     |      0.96875      |\n",
      "+------------------+-------------------+\n",
      "\n",
      "Epoch  7/12:\n",
      "Training: 100% |██████████| 1875/1875 [00:21<00:00, 86.32Batch/s, CrossEntropyLoss=1.47, accuracy=1]     \n",
      "Validating: 100% |██████████| 313/313 [00:03<00:00, 95.63Batch/s, CrossEntropyLoss=1.5, accuracy=0.938]  \n",
      "\n",
      "Summary:\n",
      "+------------------+-------------------+\n",
      "|     Metrics      |      Values       |\n",
      "+------------------+-------------------+\n",
      "| CrossEntropyLoss | 1.537530541419983 |\n",
      "|     accuracy     |      0.96875      |\n",
      "+------------------+-------------------+\n",
      "\n",
      "Epoch  8/12:\n",
      "Training: 100% |██████████| 1875/1875 [00:23<00:00, 78.87Batch/s, CrossEntropyLoss=1.5, accuracy=0.969]  \n",
      "Validating: 100% |██████████| 313/313 [00:03<00:00, 100.87Batch/s, CrossEntropyLoss=1.49, accuracy=1]    \n",
      "\n",
      "Summary:\n",
      "+------------------+--------------------+\n",
      "|     Metrics      |       Values       |\n",
      "+------------------+--------------------+\n",
      "| CrossEntropyLoss | 1.5335395336151123 |\n",
      "|     accuracy     |      0.96875       |\n",
      "+------------------+--------------------+\n",
      "\n",
      "Epoch  9/12:\n",
      "Training: 100% |██████████| 1875/1875 [00:21<00:00, 86.08Batch/s, CrossEntropyLoss=1.51, accuracy=0.969] \n",
      "Validating: 100% |██████████| 313/313 [00:02<00:00, 111.92Batch/s, CrossEntropyLoss=1.48, accuracy=1]    \n",
      "\n",
      "Summary:\n",
      "+------------------+--------------------+\n",
      "|     Metrics      |       Values       |\n",
      "+------------------+--------------------+\n",
      "| CrossEntropyLoss | 1.5312724113464355 |\n",
      "|     accuracy     |      0.96875       |\n",
      "+------------------+--------------------+\n",
      "\n",
      "Epoch 10/12:\n",
      "Training: 100% |██████████| 1875/1875 [00:23<00:00, 80.36Batch/s, CrossEntropyLoss=1.48, accuracy=1]     \n",
      "Validating: 100% |██████████| 313/313 [00:03<00:00, 85.64Batch/s, CrossEntropyLoss=1.47, accuracy=1]    \n",
      "\n",
      "Summary:\n",
      "+------------------+--------------------+\n",
      "|     Metrics      |       Values       |\n",
      "+------------------+--------------------+\n",
      "| CrossEntropyLoss | 1.5279436111450195 |\n",
      "|     accuracy     |      0.96875       |\n",
      "+------------------+--------------------+\n",
      "\n",
      "Epoch 11/12:\n",
      "Training: 100% |██████████| 1875/1875 [00:23<00:00, 78.80Batch/s, CrossEntropyLoss=1.57, accuracy=0.875] \n",
      "Validating: 100% |██████████| 313/313 [00:03<00:00, 99.29Batch/s, CrossEntropyLoss=1.48, accuracy=1]     \n",
      "\n",
      "Summary:\n",
      "+------------------+--------------------+\n",
      "|     Metrics      |       Values       |\n",
      "+------------------+--------------------+\n",
      "| CrossEntropyLoss | 1.5247350931167603 |\n",
      "|     accuracy     |      0.96875       |\n",
      "+------------------+--------------------+\n",
      "\n",
      "Epoch 12/12:\n",
      "Training: 100% |██████████| 1875/1875 [00:24<00:00, 75.98Batch/s, CrossEntropyLoss=1.47, accuracy=1]    \n",
      "Validating: 100% |██████████| 313/313 [00:03<00:00, 103.04Batch/s, CrossEntropyLoss=1.46, accuracy=1]    \n",
      "\n",
      "Summary:\n",
      "+------------------+--------------------+\n",
      "|     Metrics      |       Values       |\n",
      "+------------------+--------------------+\n",
      "| CrossEntropyLoss | 1.5225495100021362 |\n",
      "|     accuracy     |      0.96875       |\n",
      "+------------------+--------------------+\n",
      "> 2022-12-26 13:51:30,478 [error] Traceback (most recent call last):\n",
      "  File \"/User/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/errors.py\", line 76, in raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/conda/lib/python3.7/site-packages/requests/models.py\", line 941, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: http://mlrun-api:8080/api/v1/projects/horovod-pytorch-test-guyl/artifacts/2e706fcac6014bfdb5b6f3c3a1ad4682/training_job_training_CrossEntropyLoss.html\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/User/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/runtimes/local.py\", line 427, in exec_from_params\n",
      "    val = handler(**kwargs)\n",
      "  File \"/User/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/run.py\", line 2030, in wrapper\n",
      "    func_outputs = func(*args, **kwargs)\n",
      "  File \"././scripts/mnist_trainer.py\", line 102, in train\n",
      "    context=context\n",
      "  File \"/User/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/frameworks/pytorch/__init__.py\", line 197, in train\n",
      "    use_horovod=use_horovod,\n",
      "  File \"/User/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/frameworks/pytorch/mlrun_interface.py\", line 210, in train\n",
      "    if not self._callbacks_handler.on_epoch_end(epoch=epoch):\n",
      "  File \"/User/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/frameworks/pytorch/callbacks_handler.py\", line 205, in on_epoch_end\n",
      "    epoch=epoch,\n",
      "  File \"/User/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/frameworks/pytorch/callbacks_handler.py\", line 663, in _run_callbacks\n",
      "    result = method(*args, **kwargs)\n",
      "  File \"/User/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/frameworks/pytorch/callbacks/mlrun_logging_callback.py\", line 166, in on_epoch_end\n",
      "    self._logger.log_epoch_to_context(epoch=epoch)\n",
      "  File \"/User/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/frameworks/_dl_common/loggers/mlrun_logger.py\", line 135, in log_epoch_to_context\n",
      "    artifact_path=self._context.artifact_path,\n",
      "  File \"/User/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/execution.py\", line 639, in log_artifact\n",
      "    **kwargs,\n",
      "  File \"/User/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/artifacts/manager.py\", line 226, in log_artifact\n",
      "    self._log_to_db(db_key, producer.project, producer.inputs, item)\n",
      "  File \"/User/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/artifacts/manager.py\", line 249, in _log_to_db\n",
      "    project=project,\n",
      "  File \"/User/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/db/httpdb.py\", line 656, in store_artifact\n",
      "    self.api_call(\"POST\", endpoint_path, error, params=params, body=body)\n",
      "  File \"/User/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/db/httpdb.py\", line 227, in api_call\n",
      "    mlrun.errors.raise_for_status(response, error)\n",
      "  File \"/User/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/errors.py\", line 84, in raise_for_status\n",
      "    ) from exc\n",
      "mlrun.errors.MLRunInternalServerError: 500 Server Error: Internal Server Error for url: http://mlrun-api:8080/api/v1/projects/horovod-pytorch-test-guyl/artifacts/2e706fcac6014bfdb5b6f3c3a1ad4682/training_job_training_CrossEntropyLoss.html: store artifact horovod-pytorch-test-guyl/2e706fcac6014bfdb5b6f3c3a1ad4682/training_job_training_CrossEntropyLoss.html details: {'reason': 'OperationalError(\\'(pymysql.err.OperationalError) (2003, \"Can\\\\\\'t connect to MySQL server on \\\\\\'mlrun-db\\\\\\' ([Errno 111] Connection refused)\")\\')'}\n",
      "\n"
     ]
    },
    {
     "ename": "MLRunInternalServerError",
     "evalue": "500 Server Error: Internal Server Error for url: http://mlrun-api:8080/api/v1/run/horovod-pytorch-test-guyl/2e706fcac6014bfdb5b6f3c3a1ad4682?iter=0: store run horovod-pytorch-test-guyl/2e706fcac6014bfdb5b6f3c3a1ad4682 details: {'reason': 'OperationalError(\"(pymysql.err.OperationalError) (2013, \\'Lost connection to MySQL server during query\\')\")'}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m~/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/errors.py\u001B[0m in \u001B[0;36mraise_for_status\u001B[0;34m(response, message)\u001B[0m\n\u001B[1;32m     75\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 76\u001B[0;31m         \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_for_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     77\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mrequests\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mHTTPError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/conda/lib/python3.7/site-packages/requests/models.py\u001B[0m in \u001B[0;36mraise_for_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    940\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mhttp_error_msg\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 941\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mHTTPError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhttp_error_msg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    942\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mHTTPError\u001B[0m: 500 Server Error: Internal Server Error for url: http://mlrun-api:8080/api/v1/run/horovod-pytorch-test-guyl/2e706fcac6014bfdb5b6f3c3a1ad4682?iter=0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mMLRunInternalServerError\u001B[0m                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-429c1b65bc6b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0;34m\"n_epochs\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mN_EPOCHS\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     },\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0mlocal\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m )\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/runtimes/base.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, runspec, handler, name, project, params, inputs, out_path, workdir, artifact_path, watch, schedule, hyperparams, hyper_param_options, verbose, scrape_metrics, local, local_code_path, auto_build)\u001B[0m\n\u001B[1;32m    357\u001B[0m                 \u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    358\u001B[0m                 \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 359\u001B[0;31m                 \u001B[0martifact_path\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    360\u001B[0m             )\n\u001B[1;32m    361\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/runtimes/base.py\u001B[0m in \u001B[0;36m_run_local\u001B[0;34m(self, runspec, schedule, local_code_path, project, name, workdir, handler, params, inputs, artifact_path)\u001B[0m\n\u001B[1;32m    569\u001B[0m             \u001B[0martifact_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0martifact_path\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    570\u001B[0m             \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mspec\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 571\u001B[0;31m             \u001B[0mallow_empty_resources\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mspec\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mallow_empty_resources\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    572\u001B[0m         )\n\u001B[1;32m    573\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/run.py\u001B[0m in \u001B[0;36mrun_local\u001B[0;34m(task, command, name, args, workdir, project, tag, secrets, handler, params, inputs, artifact_path, mode, allow_empty_resources)\u001B[0m\n\u001B[1;32m    197\u001B[0m         \u001B[0mparams\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    198\u001B[0m         \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 199\u001B[0;31m         \u001B[0martifact_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0martifact_path\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    200\u001B[0m     )\n\u001B[1;32m    201\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/runtimes/base.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, runspec, handler, name, project, params, inputs, out_path, workdir, artifact_path, watch, schedule, hyperparams, hyper_param_options, verbose, scrape_metrics, local, local_code_path, auto_build)\u001B[0m\n\u001B[1;32m    441\u001B[0m             \u001B[0;31m# single run\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    442\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 443\u001B[0;31m                 \u001B[0mresp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexecution\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    444\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mwatch\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkind\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"handler\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"local\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m                     \u001B[0mstate\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_db\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/runtimes/local.py\u001B[0m in \u001B[0;36m_run\u001B[0;34m(self, runobj, execution)\u001B[0m\n\u001B[1;32m    308\u001B[0m             \u001B[0mfn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_handler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhandler\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    309\u001B[0m             \u001B[0mglobal_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcontext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 310\u001B[0;31m             \u001B[0msout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mserr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexec_from_params\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrunobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    311\u001B[0m             \u001B[0mlog_std\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_db_conn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrunobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mserr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskip\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_child\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshow\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    312\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/runtimes/local.py\u001B[0m in \u001B[0;36mexec_from_params\u001B[0;34m(handler, runobj, context, cwd)\u001B[0m\n\u001B[1;32m    439\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    440\u001B[0m         \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"return\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 441\u001B[0;31m     \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcommit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    442\u001B[0m     \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_logger_level\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mold_level\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    443\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mstdout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetvalue\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/execution.py\u001B[0m in \u001B[0;36mcommit\u001B[0;34m(self, message, completed)\u001B[0m\n\u001B[1;32m    850\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate_child_iterations\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommit_children\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcompleted\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcompleted\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    851\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_last_update\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnow_date\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 852\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_update_db\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    853\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcompleted\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miteration\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    854\u001B[0m             \u001B[0mmlrun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mruntimes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mglobal_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/execution.py\u001B[0m in \u001B[0;36m_update_db\u001B[0;34m(self, commit, message)\u001B[0m\n\u001B[1;32m    954\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_rundb\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    955\u001B[0m                 self._rundb.store_run(\n\u001B[0;32m--> 956\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_uid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mproject\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    957\u001B[0m                 )\n\u001B[1;32m    958\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/db/httpdb.py\u001B[0m in \u001B[0;36mstore_run\u001B[0;34m(self, struct, uid, project, iter)\u001B[0m\n\u001B[1;32m    474\u001B[0m         \u001B[0merror\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf\"store run {project}/{uid}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    475\u001B[0m         \u001B[0mbody\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_as_json\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstruct\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 476\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapi_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"POST\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merror\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbody\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbody\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    477\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    478\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mupdate_run\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mupdates\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproject\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/db/httpdb.py\u001B[0m in \u001B[0;36mapi_call\u001B[0;34m(self, method, path, error, params, body, json, headers, timeout, version)\u001B[0m\n\u001B[1;32m    225\u001B[0m                     \u001B[0merror_details\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf\"details: {error_details}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    226\u001B[0m                     \u001B[0merror\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf\"{error} {error_details}\"\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0merror\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0merror_details\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 227\u001B[0;31m                     \u001B[0mmlrun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_for_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merror\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    228\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    229\u001B[0m             \u001B[0mmlrun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_for_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merror\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pythonlibs/jupyter-guyl/lib/python3.7/site-packages/mlrun/errors.py\u001B[0m in \u001B[0;36mraise_for_status\u001B[0;34m(response, message)\u001B[0m\n\u001B[1;32m     82\u001B[0m             raise STATUS_ERRORS[response.status_code](\n\u001B[1;32m     83\u001B[0m                 \u001B[0merror_message\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 84\u001B[0;31m             ) from exc\n\u001B[0m\u001B[1;32m     85\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mMLRunHTTPError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merror_message\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mMLRunInternalServerError\u001B[0m: 500 Server Error: Internal Server Error for url: http://mlrun-api:8080/api/v1/run/horovod-pytorch-test-guyl/2e706fcac6014bfdb5b6f3c3a1ad4682?iter=0: store run horovod-pytorch-test-guyl/2e706fcac6014bfdb5b6f3c3a1ad4682 details: {'reason': 'OperationalError(\"(pymysql.err.OperationalError) (2013, \\'Lost connection to MySQL server during query\\')\")'}"
     ]
    }
   ],
   "source": [
    "# Run as a job:\n",
    "job_run = job_function.run(\n",
    "    name=\"training_job\",\n",
    "    params={\n",
    "        \"scripts_path\": SCRIPTS_PATH,\n",
    "        \"data_path\": DATA_PATH,\n",
    "        \"n_epochs\": N_EPOCHS,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Store results:\n",
    "job_time = job_run.status.results['time']\n",
    "job_accuracy = job_run.status.results['validation_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6732fae9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Run As a MPIJob\n",
    "\n",
    "Run the training as a `mpijob` and storing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1cc7a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run as a mpijob:\n",
    "mpijob_run = mpijob_function.run(\n",
    "    name=\"training_mpijob\",\n",
    "    params={\n",
    "        \"scripts_path\": SCRIPTS_PATH,\n",
    "        \"data_path\": DATA_PATH,\n",
    "        \"n_epochs\": N_EPOCHS,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Store results:\n",
    "mpijob_time = mpijob_run.status.results['time']\n",
    "mpijob_accuracy = mpijob_run.status.results['validation_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a581b5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5. Compare Runtimes\n",
    "\n",
    "1. Print a summary message.\n",
    "2. Verify that:\n",
    "  * The mpijob run took less time (only in stronger machines). \n",
    "  * The accuracy value is equal between the runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798cda53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Delete the test outputs:\n",
    "shutil.rmtree(DATA_PATH)\n",
    "shutil.rmtree(SCRIPTS_PATH)\n",
    "\n",
    "# Delete the MLRun project:\n",
    "mlrun.get_run_db().delete_project(name=project.name, deletion_strategy=\"cascading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd5507",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print the test's collected results:\n",
    "print(\n",
    "    f\"Job:\\n\" \n",
    "    f\"\\t{'%.2f' % job_time} Seconds\\n\"\n",
    "    f\"\\tAccuracy: {job_accuracy}\"\n",
    ")\n",
    "print(\n",
    "    f\"Open MPI Job (Horovod):\\n\"\n",
    "    f\"\\t{'%.2f' % mpijob_time} Seconds\\n\"\n",
    "    f\"\\tAccuracy: {mpijob_accuracy}\\n\"\n",
    ")\n",
    "\n",
    "#  Verification: (Only possible to test on a stronger machine as the test requires big data and longer training)\n",
    "# assert mpijob_time < job_time\n",
    "# assert np.isclose(job_accuracy, mpijob_accuracy, atol=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50775755",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}